---
title: "R Notebook"
output: html_notebook
---


```{r}
set.seed(03031988)
library(data.table)

# Comment this out when data does not need to be reloaded
rm(train)

if (!exists('train')) { train <- data.table(read.csv('train.csv', na.strings="-1")) }
if (!exists('test')) { test <- data.table(read.csv('test.csv', na.strings="-1")) }

```

## Data transformation
Info from the Kaggle page:
* The **_bin** suffix means that it is a dummy variable. 
* The **_cat** suffix means that it is a categorical value.
* **-1** means that the value is missing. This has already been taken care of when loading the data.

```{r}
# Transform categorical values - train
cols <- grep("\\_cat",names(train),value=T)
train[, (cols) := lapply(.SD, as.factor), .SDcols=cols]
# train[cols] <- lapply(train[cols],as.factor)


# Transform boolean values - train (also target)
cols <- grep("\\_bin|target",names(train),value=T)
train[, (cols) := lapply(.SD, as.logical), .SDcols=cols]

# Transform categorical values - test
cols <- grep("\\_cat",names(train),value=T)
test[, (cols) := lapply(.SD, as.factor), .SDcols=cols]

# Transform boolean values - test
cols <- grep("\\_bin",names(train),value=T)
test[, (cols) := lapply(.SD, as.logical), .SDcols=cols]

rm(cols)

# Remove id
train <- subset(train,select=c(-id))

# Make backup of train
trainBackup <- train
```

## Exploratory analysis

The fact that the claim rate is very low can make the prediction very hard. The _specificity_ will probably be very high, but the _sensitivity_ won't be.

```{r}
# Dimensions of the data frame
dim(train)

# Names of the variables
names(train)

# Summary and overview of the data
str(train)

# What is the claim rate?
sum(train$target) / nrow(train)

```

How many complete rows are there?

There is also quite a lot of rows which contain NA's. 
```{r}
# Absolute
nrow(train[complete.cases(train),])
# Relative
nrow(train[complete.cases(train),]) / nrow(train)

# For computing speed purposes, code is written by testing it on a 10k non-missing data record data set.
# Uncomment next line to work with complete rows only
train <- train[complete.cases(train),]
# Uncomment the next line to work with a sample of 10k rows.
train <- train[sample(nrow(train),size = 10000,replace = F),]
```

## Fitting all variables
```{r}
lmAll <- glm(target~.,data=train)
summary(lmAll)
```

## Feature selection
### Filter method
#### Correlation matrix
Here is a correlation matrix. The following variables are highly correlated (arbitrary cutoff at 0.6):
* **ps_ind_14** and ps_ind_12_bin
* ps_reg_01 and ps_reg_03
* ps_car_13 and ps_car_12
* ps_ind_17_bin and ps_ind_16_bin
* **ps_ind_14** and ps_ind_11_bin

```{r}
# Remove categorical and target column
cols <- grep("\\_cat|target",names(train),value=T,invert=T)

# Generate correlation matrix with absolute value of correlation
corMatrixWide <- abs(cor(train[,..cols]))


# Convert correlation matrix to long format
corMatrixLong <- data.table(melt(corMatrixWide))

# Remove self-correlation rows
corMatrixLong <- corMatrixLong[Var1 != Var2]

# Order from highly-correlate to not correlatied
corMatrixLong <- corMatrixLong[order(-value),]

# Remove dupes (DANGER - what if different covariates have same correlation coefficient?)
corMatrixLong <- corMatrixLong[-seq(0,nrow(corMatrixLong),2),]

# Remove highly correlated values
abundantFeatures <- as.character(unique(corMatrixLong[value > 0.6,]$Var2))
trainF <- train[, (abundantFeatures) := NULL]

# Clean up
rm(cols)
rm(abundantFeatures)
```

#### Decision trees
To find the most important features, we can use decision trees. However, the algorithm does not appear to find any significant features as it is only producing a root. Which is very problematic because decision trees are generally a good way to classify imbalanced classes.

```{r}
library(rpart)
# trainTree <- rpart(target~.,data=trainF,method='class',control=rpart.control(minsplit=1, minbucket=1, cp=0.001))
# plot(trainTree)
```

#### Individual logit regression
In the following section, I run a bivariate logit regression for every variable to determine the importance of each variable individually. This also turns out not to be very informative.

```{r}
glmVars <- data.table(variable = character(),AIC=integer(),deviance=integer(),p=integer())
for (i in 2:ncol(trainF)) {
    v <- names(trainF)[i]
    model <- glm(formula(paste("target~",v)),family="binomial",data=trainF)
    modelSum <- summary(model)
    newrow <- data.table(variable=v,AIC=modelSum$aic,deviance=modelSum$deviance,p=modelSum$coefficients[8])
    glmVars <- rbind(glmVars,newrow)
}
glmVars <- glmVars[order(deviance),]

# Clean up
rm(model)
rm(modelSum)
rm(newrow)
rm(v)
```

### Wrapper method

We can use the bestglm or regsubsets package to find out the best variables for each n where n is the amount of predictors. This is slow as hell because it is a huge data set, even when sampled, as it has 2^57 models.

```{r}
library(regsubsets)
# lmReg <- regsubsets(target~.,data=train,nvmax=57,really.big=T)
```

What about forward and backward selection. Also very slow. Time to go to other solution.

```{r}
# Backward
# lmBwd <- regsubsets(target~.,data=train,method="backward")
```

## Undersampling

It appears we have a serious problem of engineering features and making decent predictions because one of the classes is seriously underrepresented. Since the cardinality overrepresented label is very high, undersampling should be our next step.

```{r}
table(train$target)

# ROSE package does not seem to work at all.
# mlr package can't handle logical columns.
# Not a big fan of caret package because it dumbs things down too much. But here goes.
library(caret)
rfModel <- caret::train(target ~ ., data=train, method = "rf", 
                        preProcess = c("scale","center"), na.action = na.omit,
                        trControl = trainControl(method = "repeatedcv",number = 10,repeats = 3, verboseIter=F))

```